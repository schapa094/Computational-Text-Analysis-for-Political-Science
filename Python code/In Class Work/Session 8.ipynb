{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 8 Outline\n",
    "\n",
    "- Go through Excercises of Session 7\n",
    "- Pos Tagging\n",
    "- Senses\n",
    "- Named Entity Recognition\n",
    "- Excercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Ashrakat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "from numpy import random # random data\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import codecs\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pprint\n",
    "import random\n",
    "from urllib import request\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos-Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In POS tagging the probability of a POS in the previous words conditions the probability of the tag for the current word.\n",
    "\n",
    "check categories of pos tagger here: https://www.nltk.org/book/ch05.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent=\"I need access to the cloud\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- is \"access here a noun or a verb\"\n",
    "\n",
    "Two probablities evaluated:\n",
    "1. Probability of flies being a verb or a noun\n",
    "2. Probablity of a verb following a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('need', 'VBP'), ('access', 'NN'), ('to', 'TO'), ('the', 'DT'), ('cloud', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sent = nltk.word_tokenize(sent)\n",
    "sent = nltk.pos_tag(sent)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos-tagged [('DAMN', 'NNP'), ('Fans', 'NNS'), ('took', 'VBD'), ('to', 'TO'), ('Twitter', 'NNP'), ('in', 'IN'), ('their', 'PRP$'), ('droves', 'NNS'), ('to', 'TO'), ('commend', 'VB'), ('the', 'DT'), ('team', 'NN'), ('and', 'CC'), ('their', 'PRP$'), ('supporters', 'NNS'), ('for', 'IN'), ('their', 'PRP$'), ('classy', 'JJ'), ('performance', 'NN'), ('that', 'IN'), ('many', 'JJ'), ('credited', 'VBD'), ('as', 'IN'), ('the', 'DT'), ('highlight', 'NN'), ('of', 'IN'), ('Euro-2016', 'NNP'), ('so', 'IN'), ('far', 'RB'), ('.', '.')]\n",
      "\n",
      "lemmatized ['damn', 'fan', 'took', 'to', 'twitter', 'in', 'their', 'drove', 'to', 'commend', 'the', 'team', 'and', 'their', 'supporter', 'for', 'their', 'classy', 'performance', 'that', 'many', 'credited', 'a', 'the', 'highlight', 'of', 'euro-2016', 'so', 'far', '.']\n"
     ]
    }
   ],
   "source": [
    "import codecs, nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "dataset = codecs.open(\"/Users/Ashrakat/Desktop/rt_dataset.tsv\", \"r\", \"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "article = dataset[50].split(\"\\t\")[3]\n",
    "\n",
    "# split into sentences\n",
    "sentences = nltk.sent_tokenize(article) \n",
    "\n",
    "sentence = nltk.word_tokenize(sentences[4])\n",
    "\n",
    "# you use the pos-tagger (it gives you back a list of tuples (word,pos))\n",
    "pos_sentence = nltk.pos_tag(sentence)\n",
    "print(\"pos-tagged\",pos_sentence)\n",
    "\n",
    "lemma_word = [wordnet_lemmatizer.lemmatize(token.lower(),\"x\") if \"x\" in pos else wordnet_lemmatizer.lemmatize(token.lower()) for token,pos in pos_sentence]\n",
    "print()\n",
    "print (\"lemmatized\", lemma_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "stop_word_list = stopwords.words('english')\n",
    "\n",
    "# input should be a string\n",
    "def nlp_pipeline1(text):\n",
    "    \n",
    "    # if you want you can split in sentences - i'm usually skipping this step\n",
    "    # text = nltk.sent_tokenize(text) \n",
    "    text=text.lower()\n",
    "    \n",
    "    #tokenize words for each sentence\n",
    "    text = nltk.word_tokenize(text)\n",
    "   \n",
    "    # remove punctuation and numbers\n",
    "    text = [token for token in text if token not in exclude and token.isalpha()]\n",
    "    \n",
    "    # remove stopwords - be careful with this step    \n",
    "    text = [token for token in text if token not in stop_word_list]\n",
    "    \n",
    "        # pos tagger\n",
    "    text = nltk.pos_tag(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Sep, 2016 14:08</td>\n",
       "      <td>Putin: We don’t approve of WADA hackers, but i...</td>\n",
       "      <td>news</td>\n",
       "      <td>We don’t approve of what hackers do, but what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 Sep, 2016 22:33</td>\n",
       "      <td>Hillary Clinton diagnosed with pneumonia, canc...</td>\n",
       "      <td>usa</td>\n",
       "      <td>Dr. Lisa Bardack, Clinton’s personal doctor s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 Dec, 2016 20:15</td>\n",
       "      <td>Ronaldinho and Riquelme offer to come out of r...</td>\n",
       "      <td>sport</td>\n",
       "      <td>READ MORE: 71 dead after plane carrying Brazil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 Feb, 2016 21:13</td>\n",
       "      <td>NATO &amp; European leaders whip up hysteria over ...</td>\n",
       "      <td>news</td>\n",
       "      <td>“The leaders of NATO member states and a numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Apr, 2016 18:01</td>\n",
       "      <td>US ‘Gremlin’ drones designed to cause missile ...</td>\n",
       "      <td>usa</td>\n",
       "      <td>Four firms, including fighter jet manufacturer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title   \\\n",
       "0  16 Sep, 2016 14:08   Putin: We don’t approve of WADA hackers, but i...   \n",
       "1  11 Sep, 2016 22:33   Hillary Clinton diagnosed with pneumonia, canc...   \n",
       "2   2 Dec, 2016 20:15   Ronaldinho and Riquelme offer to come out of r...   \n",
       "3   9 Feb, 2016 21:13   NATO & European leaders whip up hysteria over ...   \n",
       "4   5 Apr, 2016 18:01   US ‘Gremlin’ drones designed to cause missile ...   \n",
       "\n",
       "  topic                                             content  \n",
       "0   news  We don’t approve of what hackers do, but what ...  \n",
       "1    usa   Dr. Lisa Bardack, Clinton’s personal doctor s...  \n",
       "2  sport  READ MORE: 71 dead after plane carrying Brazil...  \n",
       "3   news  “The leaders of NATO member states and a numbe...  \n",
       "4    usa  Four firms, including fighter jet manufacturer...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = pd.read_csv('/Users/Ashrakat/Desktop/rt_dataset.tsv',delimiter=\"\\t\")\n",
    "rt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt=rt[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt[\"content\"]=rt[\"content\"].apply(nlp_pipeline1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Sep, 2016 14:08</td>\n",
       "      <td>Putin: We don’t approve of WADA hackers, but i...</td>\n",
       "      <td>news</td>\n",
       "      <td>[(approve, VB), (hackers, NNS), (done, VBN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 Sep, 2016 22:33</td>\n",
       "      <td>Hillary Clinton diagnosed with pneumonia, canc...</td>\n",
       "      <td>usa</td>\n",
       "      <td>[(lisa, JJ), (bardack, NN), (clinton, NN), (pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 Dec, 2016 20:15</td>\n",
       "      <td>Ronaldinho and Riquelme offer to come out of r...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[(read, VBN), (dead, JJ), (plane, NN), (carryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 Feb, 2016 21:13</td>\n",
       "      <td>NATO &amp; European leaders whip up hysteria over ...</td>\n",
       "      <td>news</td>\n",
       "      <td>[(leaders, NNS), (nato, VBP), (member, NN), (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Apr, 2016 18:01</td>\n",
       "      <td>US ‘Gremlin’ drones designed to cause missile ...</td>\n",
       "      <td>usa</td>\n",
       "      <td>[(four, CD), (firms, NNS), (including, VBG), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title   \\\n",
       "0  16 Sep, 2016 14:08   Putin: We don’t approve of WADA hackers, but i...   \n",
       "1  11 Sep, 2016 22:33   Hillary Clinton diagnosed with pneumonia, canc...   \n",
       "2   2 Dec, 2016 20:15   Ronaldinho and Riquelme offer to come out of r...   \n",
       "3   9 Feb, 2016 21:13   NATO & European leaders whip up hysteria over ...   \n",
       "4   5 Apr, 2016 18:01   US ‘Gremlin’ drones designed to cause missile ...   \n",
       "\n",
       "  topic                                             content  \n",
       "0   news  [(approve, VB), (hackers, NNS), (done, VBN), (...  \n",
       "1    usa  [(lisa, JJ), (bardack, NN), (clinton, NN), (pe...  \n",
       "2  sport  [(read, VBN), (dead, JJ), (plane, NN), (carryi...  \n",
       "3   news  [(leaders, NNS), (nato, VBP), (member, NN), (s...  \n",
       "4    usa  [(four, CD), (firms, NNS), (including, VBG), (...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt.content = rt.content.apply(lambda x: [(t[0],) for t in x if t[1]=='VB' or t[1]=='VBN'])\n",
    "#keep element 0 if elemet 1 is VB or VBNs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Sep, 2016 14:08</td>\n",
       "      <td>Putin: We don’t approve of WADA hackers, but i...</td>\n",
       "      <td>news</td>\n",
       "      <td>[(approve,), (done,), (cited,), (banned,), (re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 Sep, 2016 22:33</td>\n",
       "      <td>Hillary Clinton diagnosed with pneumonia, canc...</td>\n",
       "      <td>usa</td>\n",
       "      <td>[(released,), (given,), (fallen,), (driven,), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 Dec, 2016 20:15</td>\n",
       "      <td>Ronaldinho and Riquelme offer to come out of r...</td>\n",
       "      <td>sport</td>\n",
       "      <td>[(read,), (joined,), (come,), (club,), (taken,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 Feb, 2016 21:13</td>\n",
       "      <td>NATO &amp; European leaders whip up hysteria over ...</td>\n",
       "      <td>news</td>\n",
       "      <td>[(support,), (approved,), (involved,), (known,)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Apr, 2016 18:01</td>\n",
       "      <td>US ‘Gremlin’ drones designed to cause missile ...</td>\n",
       "      <td>usa</td>\n",
       "      <td>[(brought,), (unmanned,), (named,), (take,), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title   \\\n",
       "0  16 Sep, 2016 14:08   Putin: We don’t approve of WADA hackers, but i...   \n",
       "1  11 Sep, 2016 22:33   Hillary Clinton diagnosed with pneumonia, canc...   \n",
       "2   2 Dec, 2016 20:15   Ronaldinho and Riquelme offer to come out of r...   \n",
       "3   9 Feb, 2016 21:13   NATO & European leaders whip up hysteria over ...   \n",
       "4   5 Apr, 2016 18:01   US ‘Gremlin’ drones designed to cause missile ...   \n",
       "\n",
       "  topic                                             content  \n",
       "0   news  [(approve,), (done,), (cited,), (banned,), (re...  \n",
       "1    usa  [(released,), (given,), (fallen,), (driven,), ...  \n",
       "2  sport  [(read,), (joined,), (come,), (club,), (taken,...  \n",
       "3   news   [(support,), (approved,), (involved,), (known,)]  \n",
       "4    usa  [(brought,), (unmanned,), (named,), (take,), (...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-Sense-Disambiguation\n",
    "\n",
    "### WSD is the task of assigning a sense to a word, given a context.\n",
    "\n",
    "- Words are ambigous\n",
    "- Language is very contextual and the meanings of the words depend upon the context in which you are using it.\n",
    "- The sense of a word is a way of identifying how we use a given word by associating its definition\n",
    "\n",
    "read more: https://www.linkedin.com/pulse/wordnet-word-sense-disambiguation-wsd-nltk-aswathi-nambiar/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "\n",
    "- using Thesaurus (WordNet is a large lexical database of English.)\n",
    "- Wordnet includes for example synonyms and annonyms\n",
    "- using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider the two sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lesk** is one of the algorithms that help disambiguate and estimate the sense of words in a sentence\n",
    "\n",
    "1. Retrieve all sense definitions of target word \n",
    "2. Compare each sense definition with the sense definitions of the other words in context \n",
    "3. Choose the sense with the highest overlap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.wsd import lesk\n",
    "#lesk is one of the algorithms that help disambiguate and estimate the sense of words in a sentence\n",
    "\n",
    "sent1=\"the sea bass is delicious\"\n",
    "sent2=\"musical bass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('sea_bass.n.01')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(sent1.split(),\"bass\",\"n\")\n",
    "\n",
    "#lemma.pos.countnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.07')\n"
     ]
    }
   ],
   "source": [
    "print(lesk(sent2.split(),\"bass\",\"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Rustan Magomedovich Aselderov (Abu Muhammad), born in 1981, the leader of the Vilayat Kavkaz section of the Islamic State international terrorist group, was among the militants eliminated alongside four of his close associates,” the FSB said in a statement. The terrorist cell was neutralized near the southern Russian city of Makhachkala, the capital of the Republic of Dagestan. Aselderov and four other militants were found hiding out in a house in the village. After the hideout was surrounded, the police started negotiations and asked the militants to surrender. In response, the terrorists fired automatic weapons and were killed by return fire. None of the officers taking part in the operation were injured. A large cache of weapons was then discovered in the hideout, including automatic rifles, munitions and explosives. The FSB said Aselderov was one of the organizers of the terrorist attack on Volgograd’s train station on December 29, 2013, which killed 18 people and left dozens injured after a suicide bomber blew herself up at the station’s entrance. Another suicide bomber targeted civilians in a Volgograd trolleybus on December 30, killing 16 people and injuring 25 others. “From all the terrorist acts carried out by [Aselderov and his henchmen] the terrorist acts targeting public transport and railway station in Volgograd, which inflicted multiple casualties, are the bloodiest,” the FSB said in a statement. But Aselderov is also suspected to be complicit in the double explosions that hit the Astrakhan-Makhachkala highway in May 2012, killing 40 people and injuring over a hundred. The militant was also involved in the planning of a foiled terrorist attack on Moscow’s Red Square, in which two female suicide bombers were supposed to detonate on December 31, 2010. The plot was uncovered by the FSB. He is also believed to be behind the murder of an imam in the village of Karamakhi, Dagestan and the killing of the same village’s head in 2015. Aselderov has been known to Russian law enforcement as an active member of Dagestan terrorist cells since 2007. In 2012, he became in charge of Dagestan’s unit of the internationally recognized terrorist organization “Imarat Kavkaz.” In 2014, he was “one of the first” to pledge allegiance to Islamic State. Бывший \"амир Дагестана\" Рустам Асельдеров.Присягнул \"Исламскому Государству\"https://t.co/TMyevlWxbjpic.twitter.com/dVy3M4V6J2 In late June 2015, Aselderov was appointed the head of the so-called Vilayat Kavkaz, established on the Russian territory by Islamic State, on the orders of its leader, Abu Bakr al-Baghdadi. Among his “duties” as an emir were the planning of terrorist acts in Russia’s Northern Caucasus and in central Russia, the FSB said.In September 2015, the US Treasury imposed economic sanctions on Aselderov adding him to the list of specially designated global terrorists. He was also included in UN Security Council’s sanctions list and was wanted internationally. \n"
     ]
    }
   ],
   "source": [
    "#rt dataset\n",
    "article = dataset[261].split(\"\\t\")[3]\n",
    "\n",
    "print (article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rustan', 'magomedovich', 'aselderov', 'abu', 'muhammad', 'bear', 'leader', 'vilayat', 'kavkaz', 'section', 'islamic', 'state', 'international', 'terrorist', 'group', 'among', 'militant', 'eliminate', 'alongside', 'four', 'close', 'associate', 'fsb', 'say', 'statement', 'terrorist', 'cell', 'neutralize', 'near', 'southern', 'russian', 'city', 'makhachkala', 'capital', 'republic', 'dagestan', 'aselderov', 'four', 'militant', 'find', 'hide', 'house', 'village', 'hideout', 'surround', 'police', 'start', 'negotiation', 'ask', 'militant', 'surrender', 'response', 'terrorist', 'fire', 'automatic', 'weapon', 'kill', 'return', 'fire', 'none', 'officer', 'take', 'part', 'operation', 'injure', 'large', 'cache', 'weapon', 'discover', 'hideout', 'include', 'automatic', 'rifle', 'munition', 'explosive', 'fsb', 'say', 'aselderov', 'one', 'organizer', 'terrorist', 'attack', 'volgograd', 'train', 'station', 'december', 'kill', 'people', 'leave', 'dozen', 'injure', 'suicide', 'bomber', 'blow', 'station', 'entrance', 'another', 'suicide', 'bomber', 'target', 'civilian', 'volgograd', 'trolleybus', 'december', 'kill', 'people', 'injure', 'others', 'terrorist', 'act', 'carry', 'aselderov', 'henchman', 'terrorist', 'act', 'target', 'public', 'transport', 'railway', 'station', 'volgograd', 'inflict', 'multiple', 'casualty', 'bloodiest', 'fsb', 'say', 'statement', 'aselderov', 'also', 'suspect', 'complicit', 'double', 'explosion', 'hit', 'highway', 'may', 'kill', 'people', 'injure', 'hundred', 'militant', 'also', 'involve', 'planning', 'foiled', 'terrorist', 'attack', 'moscow', 'red', 'square', 'two', 'female', 'suicide', 'bomber', 'suppose', 'detonate', 'december', 'plot', 'uncover', 'fsb', 'also', 'believe', 'behind', 'murder', 'imam', 'village', 'karamakhi', 'dagestan', 'killing', 'village', 'head', 'aselderov', 'know', 'russian', 'law', 'enforcement', 'active', 'member', 'dagestan', 'terrorist', 'cell', 'since', 'become', 'charge', 'dagestan', 'unit', 'internationally', 'recognize', 'terrorist', 'organization', 'imarat', 'one', 'first', 'pledge', 'allegiance', 'islamic', 'state', 'бывший', 'амир', 'дагестана', 'рустам', 'исламскому', 'государству', 'http', 'late', 'june', 'aselderov', 'appoint', 'head', 'vilayat', 'kavkaz', 'establish', 'russian', 'territory', 'islamic', 'state', 'order', 'leader', 'abu', 'bakr', 'among', 'duty', 'emir', 'planning', 'terrorist', 'act', 'russia', 'northern', 'caucasus', 'central', 'russia', 'fsb', 'september', 'u', 'treasury', 'impose', 'economic', 'sanction', 'aselderov', 'add', 'list', 'specially', 'designate', 'global', 'terrorist', 'also', 'include', 'un', 'security', 'council', 'sanction', 'list', 'want', 'internationally']\n"
     ]
    }
   ],
   "source": [
    "def nlp_pipeline(text):\n",
    "    \n",
    "    # if you want you can split in sentences - i'm usually skipping this step\n",
    "    # text = nltk.sent_tokenize(text) \n",
    "    \n",
    "    #tokenize words for each sentence\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # pos tagger\n",
    "    text = nltk.pos_tag(text)\n",
    "\n",
    "    # lemmatizer\n",
    "    text = [wordnet_lemmatizer.lemmatize(token.lower(),\"v\")if \"V\" in pos else wordnet_lemmatizer.lemmatize(token.lower()) for token,pos in text]\n",
    "    \n",
    "    # remove punctuation and numbers\n",
    "    text = [token for token in text if token not in exclude and token.isalpha()]\n",
    "    \n",
    "    # remove stopwords - be careful with this step    \n",
    "    text = [token for token in text if token not in stop_word_list]\n",
    "\n",
    "    return text\n",
    "# let's use our pipeline!\n",
    "clean_article = nlp_pipeline(article)\n",
    "print (clean_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synset instances are the groupings of synonymous words that express the same concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dagestan 0\n",
      "амир 0\n",
      "two 3\n",
      "central 3\n",
      "injure 3\n",
      "государству 0\n",
      "december 1\n",
      "statement 7\n",
      "railway 2\n",
      "bakr 0\n",
      "moscow 1\n",
      "explosion 7\n",
      "global 2\n",
      "magomedovich 0\n",
      "cache 4\n",
      "kill 17\n",
      "another 1\n",
      "makhachkala 0\n",
      "none 4\n",
      "territory 3\n",
      "aselderov 0\n",
      "organization 7\n",
      "russia 4\n",
      "complicit 0\n",
      "act 15\n",
      "international 3\n",
      "unit 6\n",
      "discover 8\n",
      "bloodiest 2\n",
      "one 9\n",
      "late 11\n",
      "munition 4\n",
      "entrance 5\n",
      "hit 24\n",
      "surrender 6\n",
      "исламскому 0\n",
      "start 22\n",
      "may 2\n",
      "casualty 4\n",
      "karamakhi 0\n",
      "uncover 2\n",
      "un 1\n",
      "train 17\n",
      "foiled 4\n",
      "member 5\n",
      "multiple 2\n",
      "abu 0\n",
      "behind 7\n",
      "rifle 3\n",
      "carry 41\n",
      "highway 1\n",
      "four 3\n",
      "return 29\n",
      "charge 40\n",
      "want 9\n",
      "suspect 6\n",
      "duty 3\n",
      "alongside 1\n",
      "square 25\n",
      "group 5\n",
      "imarat 0\n",
      "believe 5\n",
      "fire 18\n",
      "become 4\n",
      "suicide 2\n",
      "russian 3\n",
      "dozen 2\n",
      "civilian 2\n",
      "involve 7\n",
      "ask 7\n",
      "inflict 1\n",
      "council 3\n",
      "weapon 2\n",
      "hundred 2\n",
      "say 12\n",
      "suppose 5\n",
      "list 7\n",
      "u 4\n",
      "associate 9\n",
      "section 15\n",
      "leader 2\n",
      "june 1\n",
      "дагестана 0\n",
      "planning 7\n",
      "city 3\n",
      "large 11\n",
      "sanction 7\n",
      "people 6\n",
      "impose 3\n",
      "caucasus 2\n",
      "also 1\n",
      "officer 5\n",
      "appoint 3\n",
      "fsb 2\n",
      "rustan 0\n",
      "surround 5\n",
      "trolleybus 1\n",
      "emir 1\n",
      "take 44\n",
      "рустам 0\n",
      "near 9\n",
      "red 7\n",
      "imam 1\n",
      "hideout 1\n",
      "september 1\n",
      "automatic 5\n",
      "bomber 3\n",
      "designate 6\n",
      "northern 5\n",
      "bear 15\n",
      "public 4\n",
      "since 0\n",
      "hide 6\n",
      "negotiation 2\n",
      "murder 3\n",
      "internationally 1\n",
      "security 9\n",
      "treasury 6\n",
      "vilayat 0\n",
      "establish 8\n",
      "enforcement 1\n",
      "double 21\n",
      "economic 5\n",
      "eliminate 7\n",
      "cell 7\n",
      "organizer 3\n",
      "pledge 9\n",
      "add 7\n",
      "house 14\n",
      "republic 2\n",
      "militant 4\n",
      "detonate 2\n",
      "attack 15\n",
      "henchman 1\n",
      "neutralize 6\n",
      "others 0\n",
      "plot 8\n",
      "village 3\n",
      "female 5\n",
      "recognize 9\n",
      "kavkaz 0\n",
      "capital 11\n",
      "part 18\n",
      "explosive 4\n",
      "first 16\n",
      "include 4\n",
      "find 18\n",
      "transport 11\n",
      "killing 19\n",
      "http 1\n",
      "бывший 0\n",
      "operation 11\n",
      "target 6\n",
      "islamic 1\n",
      "muhammad 2\n",
      "close 37\n",
      "know 12\n",
      "head 42\n",
      "station 6\n",
      "police 2\n",
      "specially 2\n",
      "order 24\n",
      "allegiance 2\n",
      "active 17\n",
      "leave 17\n",
      "law 7\n",
      "state 11\n",
      "southern 4\n",
      "response 7\n",
      "terrorist 1\n",
      "volgograd 1\n",
      "among 0\n",
      "blow 29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# word sense disambiguation\n",
    "\n",
    "# check documentation: http://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# let's isolate each word - you do this using a set (another type of object in python)\n",
    "\n",
    "unique_words = set(clean_article)\n",
    "\n",
    "# let's check how many senses each word has\n",
    "for word in unique_words:\n",
    "    print (word, len(wn.synsets(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank sloping land (especially the slope beside a body of water)\n",
      "textual example ['they pulled the canoe up on the bank', 'he sat on the bank of the river and watched the currents']\n",
      "hypernymy [Synset('slope.n.01')]\n",
      "hyponyms [Synset('riverbank.n.01'), Synset('waterside.n.01')]\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank a financial institution that accepts deposits and channels the money into lending activities\n",
      "textual example ['he cashed a check at the bank', 'that bank holds the mortgage on my home']\n",
      "hypernymy [Synset('financial_institution.n.01')]\n",
      "hyponyms [Synset('acquirer.n.02'), Synset('agent_bank.n.02'), Synset('commercial_bank.n.01'), Synset('credit_union.n.01'), Synset('federal_reserve_bank.n.01'), Synset('home_loan_bank.n.01'), Synset('lead_bank.n.01'), Synset('member_bank.n.01'), Synset('merchant_bank.n.01'), Synset('state_bank.n.01'), Synset('thrift_institution.n.01')]\n",
      "synonyms ['depository_financial_institution', 'bank', 'banking_concern', 'banking_company']\n",
      "antonyms []\n",
      "\n",
      "bank a long ridge or pile\n",
      "textual example ['a huge bank of earth']\n",
      "hypernymy [Synset('ridge.n.01')]\n",
      "hyponyms [Synset('bluff.n.01'), Synset('sandbank.n.01')]\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank an arrangement of similar objects in a row or in tiers\n",
      "textual example ['he operated a bank of switches']\n",
      "hypernymy [Synset('array.n.01')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank a supply or stock held in reserve for future use (especially in emergencies)\n",
      "textual example []\n",
      "hypernymy [Synset('reserve.n.02')]\n",
      "hyponyms [Synset('blood_bank.n.01'), Synset('eye_bank.n.01'), Synset('food_bank.n.01'), Synset('soil_bank.n.01')]\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank the funds held by a gambling house or the dealer in some gambling games\n",
      "textual example ['he tried to break the bank at Monte Carlo']\n",
      "hypernymy [Synset('funds.n.01')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "textual example []\n",
      "hypernymy [Synset('slope.n.01')]\n",
      "hyponyms []\n",
      "synonyms ['bank', 'cant', 'camber']\n",
      "antonyms []\n",
      "\n",
      "bank a container (usually with a slot in the top) for keeping money at home\n",
      "textual example ['the coin bank was empty']\n",
      "hypernymy [Synset('container.n.01')]\n",
      "hyponyms [Synset('piggy_bank.n.01')]\n",
      "synonyms ['savings_bank', 'coin_bank', 'money_box', 'bank']\n",
      "antonyms []\n",
      "\n",
      "bank a building in which the business of banking transacted\n",
      "textual example ['the bank is on the corner of Nassau and Witherspoon']\n",
      "hypernymy [Synset('depository.n.01')]\n",
      "hyponyms []\n",
      "synonyms ['bank', 'bank_building']\n",
      "antonyms []\n",
      "\n",
      "bank a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "textual example ['the plane went into a steep bank']\n",
      "hypernymy [Synset('flight_maneuver.n.01')]\n",
      "hyponyms [Synset('vertical_bank.n.01')]\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank tip laterally\n",
      "textual example ['the pilot had to bank the aircraft']\n",
      "hypernymy [Synset('tip.v.01')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank enclose with a bank\n",
      "textual example ['bank roads']\n",
      "hypernymy [Synset('enclose.v.03')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank do business with a bank or keep an account at a bank\n",
      "textual example ['Where do you bank in this town?']\n",
      "hypernymy [Synset('transact.v.01')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank act as the banker in a game or in gambling\n",
      "textual example []\n",
      "hypernymy [Synset('act.v.04')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank be in the banking business\n",
      "textual example []\n",
      "hypernymy [Synset('work.v.02')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank put into a bank account\n",
      "textual example ['She deposits her paycheck every month']\n",
      "hypernymy [Synset('give.v.03')]\n",
      "hyponyms [Synset('redeposit.v.01')]\n",
      "synonyms ['deposit', 'bank']\n",
      "antonyms [Lemma('withdraw.v.09.withdraw')]\n",
      "\n",
      "bank cover with ashes so to control the rate of burning\n",
      "textual example ['bank a fire']\n",
      "hypernymy [Synset('cover.v.01')]\n",
      "hyponyms []\n",
      "synonyms ['bank']\n",
      "antonyms []\n",
      "\n",
      "bank have confidence or faith in\n",
      "textual example ['We can trust in God', 'Rely on your friends', 'bank on your good education', \"I swear by my grandmother's recipes\"]\n",
      "hypernymy [Synset('believe.v.01')]\n",
      "hyponyms [Synset('count.v.08'), Synset('credit.v.04'), Synset('lean.v.04')]\n",
      "synonyms ['trust', 'swear', 'rely', 'bank']\n",
      "antonyms [Lemma('distrust.v.01.mistrust'), Lemma('distrust.v.01.distrust')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = \"bank\"\n",
    "\n",
    "senses = wn.synsets(word)\n",
    "\n",
    "for sense in senses:\n",
    "    # get definition of sense\n",
    "    print(word, sense.definition())\n",
    "    \n",
    "    # get a textual example\n",
    "    print(\"textual example\",sense.examples())\n",
    "    \n",
    "    # get hypernymy\n",
    "    print(\"hypernymy\", sense.hypernyms())\n",
    "\n",
    "    # get hyponyms\n",
    "    print(\"hyponyms\",sense.hyponyms())\n",
    "        \n",
    "    # this is a way of getting synonyms - there are others\n",
    "    print (\"synonyms\",sense.lemma_names())\n",
    "    \n",
    "    # this is for getting antonyms - works especially with adjectives \n",
    "    print (\"antonyms\",sense.lemmas()[0].antonyms())\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean sent 1: ['terrorist', 'cell', 'neutralize', 'near', 'southern', 'russian', 'city', 'makhachkala', 'capital', 'republic', 'dagestan']\n",
      "clean sent 2: ['molecule', 'use', 'light', 'energy', 'move', 'proton', 'across', 'somatic', 'cell', 'membrane', 'prove', 'unsuitable', 'crystallography']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# finding the best sense\n",
    "\n",
    "\n",
    "# let's consider two sentences where \"cell\" is mentioned\n",
    "sent1 = \"The terrorist cell was neutralized near the southern Russian city of Makhachkala,\\\n",
    "the capital of the Republic of Dagestan.\"\n",
    "sent2 = \"The molecule, which uses light energy to move protons across a somatic cell membrane,\\\n",
    "proved unsuitable for crystallography.\"\n",
    "\n",
    "# you clean the sentences using our pipeline\n",
    "clean_sent1 = nlp_pipeline(sent1)\n",
    "clean_sent2 = nlp_pipeline(sent2)\n",
    "\n",
    "print (\"clean sent 1:\", clean_sent1)\n",
    "print (\"clean sent 2:\", clean_sent2)\n",
    "print (\" \")\n",
    "\n",
    "# for each possible sense of \"cell\" you check the overlap between the definition and the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition: sloping land (especially the slope beside a body of water)\n",
      "clean definition: ['slop', 'land', 'especially', 'slope', 'beside', 'body', 'water']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: a financial institution that accepts deposits and channels the money into lending activities\n",
      "clean definition: ['financial', 'institution', 'accept', 'deposit', 'channel', 'money', 'lending', 'activity']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: a long ridge or pile\n",
      "clean definition: ['long', 'ridge', 'pile']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: an arrangement of similar objects in a row or in tiers\n",
      "clean definition: ['arrangement', 'similar', 'object', 'row', 'tier']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: a supply or stock held in reserve for future use (especially in emergencies)\n",
      "clean definition: ['supply', 'stock', 'hold', 'reserve', 'future', 'use', 'especially', 'emergency']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: {'use'}\n",
      "0 1\n",
      " \n",
      "definition: the funds held by a gambling house or the dealer in some gambling games\n",
      "clean definition: ['fund', 'hold', 'gambling', 'house', 'dealer', 'gambling', 'game']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "clean definition: ['slope', 'turn', 'road', 'track', 'outside', 'higher', 'inside', 'order', 'reduce', 'effect', 'centrifugal', 'force']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: a container (usually with a slot in the top) for keeping money at home\n",
      "clean definition: ['container', 'usually', 'slot', 'top', 'keep', 'money', 'home']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: a building in which the business of banking transacted\n",
      "clean definition: ['building', 'business', 'banking', 'transact']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "clean definition: ['flight', 'maneuver', 'aircraft', 'tip', 'laterally', 'longitudinal', 'axis', 'especially', 'turn']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: tip laterally\n",
      "clean definition: ['tip', 'laterally']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: enclose with a bank\n",
      "clean definition: ['enclose', 'bank']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: do business with a bank or keep an account at a bank\n",
      "clean definition: ['business', 'bank', 'keep', 'account', 'bank']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: act as the banker in a game or in gambling\n",
      "clean definition: ['act', 'banker', 'game', 'gamble']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: be in the banking business\n",
      "clean definition: ['banking', 'business']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: put into a bank account\n",
      "clean definition: ['put', 'bank', 'account']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: cover with ashes so to control the rate of burning\n",
      "clean definition: ['cover', 'ash', 'control', 'rate', 'burning']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n",
      "definition: have confidence or faith in\n",
      "clean definition: ['confidence', 'faith']\n",
      "intersection with sent 1: set()\n",
      "intersection with sent 2: set()\n",
      "0 0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for sense in senses:\n",
    "    # get definition of sense\n",
    "    definition =  sense.definition()\n",
    "    \n",
    "    # you clean the definition with our pipeline\n",
    "    clean_definition = nlp_pipeline(definition)\n",
    "    \n",
    "    # you check the intersection of the two sentences\n",
    "    #is there any interaction between the sentence and any of the definitions\n",
    "    inters_1 = set(clean_sent1).intersection(clean_definition)\n",
    "    inters_2 = set(clean_sent2).intersection(clean_definition)\n",
    "    \n",
    "    print (\"definition:\",definition)\n",
    "    print (\"clean definition:\", clean_definition)\n",
    "    print (\"intersection with sent 1:\", inters_1)\n",
    "    print (\"intersection with sent 2:\", inters_2)\n",
    "    print (len(inters_1),len(inters_2))\n",
    "    print (\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10'),\n",
       " Synset('bank.v.01'),\n",
       " Synset('bank.v.02'),\n",
       " Synset('bank.v.03'),\n",
       " Synset('bank.v.04'),\n",
       " Synset('bank.v.05'),\n",
       " Synset('deposit.v.02'),\n",
       " Synset('bank.v.07'),\n",
       " Synset('trust.v.01')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"bank\"\n",
    "\n",
    "senses = wn.synsets(word)\n",
    "senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a financial institution that accepts deposits and channels the money into lending activities\n"
     ]
    }
   ],
   "source": [
    "for sense in senses[1:]:\n",
    "    # get definition of sense\n",
    "    definition = sense.definition()    \n",
    "    print (definition)\n",
    "    # take all hypernyms, hyponyms and synonyms - you need to do a bit of cleaning    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 5.487223148345947 secs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', None),\n",
       " ('went', Synset('run_low.v.01')),\n",
       " ('to', None),\n",
       " ('the', None),\n",
       " ('bank', Synset('depository_financial_institution.n.01')),\n",
       " ('to', None),\n",
       " ('deposit', Synset('deposit.v.02')),\n",
       " ('my', None),\n",
       " ('money', Synset('money.n.03'))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pywsd import disambiguate\n",
    "disambiguate('I went to the bank to deposit my money')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', None),\n",
       " ('river', Synset('river.n.01')),\n",
       " ('has', None),\n",
       " ('nice', Synset('nice.s.03')),\n",
       " ('banks', Synset('bank.n.01'))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disambiguate('The river has nice banks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10'),\n",
       " Synset('bank.v.01'),\n",
       " Synset('bank.v.02'),\n",
       " Synset('bank.v.03'),\n",
       " Synset('bank.v.04'),\n",
       " Synset('bank.v.05'),\n",
       " Synset('deposit.v.02'),\n",
       " Synset('bank.v.07'),\n",
       " Synset('trust.v.01')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns = wordnet.synsets(\"bank\")\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sloping land (especially the slope beside a body of water)\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named-Entity Recognition\n",
    "\n",
    "## NER is a subtask of information extraction\n",
    "\n",
    "seeks to locate and classify pieces of  text into predefined categories such as the names of:\n",
    "- persons \n",
    "- organizations \n",
    "- locations\n",
    "- expressions of times \n",
    "- quantities\n",
    "- monetary values\n",
    "- percentages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "\n",
    "We talked about regular expressions remember\n",
    "\n",
    "**regular expression to extract:**\n",
    "- telephone numbers\n",
    "- E-mails\n",
    "- Dates\n",
    "- Prices\n",
    "- Locations (e.g., word + “river” indicates a river -> Hudson river)\n",
    "\n",
    "**context patterns**\n",
    "\n",
    "- [Person] earns [Money]\n",
    "- [PERSON] joined [ORGANIZATION]\n",
    "\n",
    "**sequence in the sentence**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillary Clinton diagnosed with pneumonia, cancels California campaign trip, 'Ellen' appearance\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import codecs, nltk\n",
    "\n",
    "dataset = codecs.open(\"/Users/Ashrakat/Desktop/rt_dataset.tsv\", \"r\", \"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "\n",
    "# how to quickly find an article from the dataset\n",
    "for k in range(len(dataset)):\n",
    "    article = dataset[k]\n",
    "    if \"Trump\" in article and \"Hillary\" in article:\n",
    "        print (article.split(\"\\t\")[1])\n",
    "        print (k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Dr./NNP\n",
      "  Lisa/NNP\n",
      "  Bardack/NNP\n",
      "  ,/,\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  personal/JJ\n",
      "  doctor/NN\n",
      "  since/IN\n",
      "  2001/CD\n",
      "  ,/,\n",
      "  released/VBN\n",
      "  a/DT\n",
      "  statement/NN\n",
      "  through/IN\n",
      "  the/DT\n",
      "  (PERSON Clinton/NNP)\n",
      "  campaign/NN\n",
      "  which/WDT\n",
      "  said/VBD\n",
      "  the/DT\n",
      "  former/JJ\n",
      "  secretary/NN\n",
      "  of/IN\n",
      "  state/NN\n",
      "  had/VBD\n",
      "  been/VBN\n",
      "  diagnosed/VBN\n",
      "  with/IN\n",
      "  pneumonia/NN\n",
      "  during/IN\n",
      "  a/DT\n",
      "  follow-up/JJ\n",
      "  examination/NN\n",
      "  regarding/VBG\n",
      "  her/PRP$\n",
      "  prolonged/JJ\n",
      "  cough/NN\n",
      "  ./.\n",
      "  Dr./NNP\n",
      "  (PERSON Lisa/NNP R./NNP Bardack/NNP)\n",
      "  ,/,\n",
      "  M.D./NNP\n",
      "  ,/,\n",
      "  (PERSON Clinton/NNP)\n",
      "  's/POS\n",
      "  doctor/NN\n",
      "  ,/,\n",
      "  says/VBZ\n",
      "  the/DT\n",
      "  (ORGANIZATION Democratic/JJ)\n",
      "  nominee/NN\n",
      "  has/VBZ\n",
      "  pneumonia/VBN\n",
      "  ./.\n",
      "  Full/JJ\n",
      "  statement/NN\n",
      "  :/:\n",
      "  pic.twitter.com/qloLbhjdZy/NN\n",
      "  (PERSON Clinton/NNP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  “/NNP\n",
      "  advised/VBD\n",
      "  to/TO\n",
      "  rest/VB\n",
      "  and/CC\n",
      "  modify/VB\n",
      "  her/PRP$\n",
      "  schedule/NN\n",
      "  ,/,\n",
      "  ”/NN\n",
      "  and/CC\n",
      "  was/VBD\n",
      "  put/VBN\n",
      "  on/IN\n",
      "  antibiotics/NNS\n",
      "  on/IN\n",
      "  Friday/NNP\n",
      "  ,/,\n",
      "  (PERSON Bardack/NNP)\n",
      "  said/VBD\n",
      "  ./.\n",
      "  “/NN\n",
      "  She/PRP\n",
      "  is/VBZ\n",
      "  now/RB\n",
      "  re-hydrated/JJ\n",
      "  and/CC\n",
      "  recovering/VBG\n",
      "  nicely/RB\n",
      "  ,/,\n",
      "  ”/NNP\n",
      "  said/VBD\n",
      "  the/DT\n",
      "  doctor/NN\n",
      "  ,/,\n",
      "  referring/VBG\n",
      "  to/TO\n",
      "  the/DT\n",
      "  earlier/JJR\n",
      "  explanation/NN\n",
      "  of/IN\n",
      "  “/NNP\n",
      "  overheating/VBG\n",
      "  and/CC\n",
      "  dehydration/NN\n",
      "  ”/NNP\n",
      "  given/VBN\n",
      "  for/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  abrupt/JJ\n",
      "  departure/NN\n",
      "  from/IN\n",
      "  the/DT\n",
      "  9/11/CD\n",
      "  commemoration/NN\n",
      "  event/NN\n",
      "  ./.\n",
      "  The/DT\n",
      "  media/NNS\n",
      "  expressed/VBD\n",
      "  suspicion/NN\n",
      "  over/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  exit/NN\n",
      "  from/IN\n",
      "  the/DT\n",
      "  event/NN\n",
      "  after/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  accounts/NNS\n",
      "  that/IN\n",
      "  she/PRP\n",
      "  had/VBD\n",
      "  stumbled/VBN\n",
      "  and/CC\n",
      "  had/VBD\n",
      "  to/TO\n",
      "  be/VB\n",
      "  helped/VBN\n",
      "  into/IN\n",
      "  her/PRP$\n",
      "  car/NN\n",
      "  ./.\n",
      "  (PERSON Video/NNP)\n",
      "  footage/NN\n",
      "  later/RB\n",
      "  emerged/VBD\n",
      "  corroborating/VBG\n",
      "  this./NN\n",
      "  “/NNP\n",
      "  Secretary/NNP\n",
      "  (PERSON Clinton/NNP)\n",
      "  attended/VBD\n",
      "  the/DT\n",
      "  September/NNP\n",
      "  11/CD\n",
      "  Commemoration/NNP\n",
      "  Ceremony/NNP\n",
      "  for/IN\n",
      "  just/RB\n",
      "  an/DT\n",
      "  hour/NN\n",
      "  and/CC\n",
      "  30/CD\n",
      "  minutes/NNS\n",
      "  this/DT\n",
      "  morning/NN\n",
      "  to/TO\n",
      "  pay/VB\n",
      "  her/PRP$\n",
      "  respects/NNS\n",
      "  and/CC\n",
      "  greet/VB\n",
      "  some/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  families/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  fallen/NN\n",
      "  ,/,\n",
      "  ”/NNP\n",
      "  campaign/NN\n",
      "  spokesman/NN\n",
      "  (PERSON Nick/NNP Merrill/NNP)\n",
      "  said/VBD\n",
      "  ./.\n",
      "  “/NN\n",
      "  During/IN\n",
      "  the/DT\n",
      "  ceremony/NN\n",
      "  ,/,\n",
      "  she/PRP\n",
      "  felt/VBD\n",
      "  overheated/VBN\n",
      "  so/RB\n",
      "  departed/JJ\n",
      "  to/TO\n",
      "  go/VB\n",
      "  to/TO\n",
      "  her/PRP$\n",
      "  daughter/NN\n",
      "  ’/NN\n",
      "  s/JJ\n",
      "  apartment/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  is/VBZ\n",
      "  feeling/VBG\n",
      "  much/JJ\n",
      "  better./NN\n",
      "  ”/VBD\n",
      "  The/DT\n",
      "  candidate/NN\n",
      "  was/VBD\n",
      "  driven/VBN\n",
      "  to/TO\n",
      "  her/PRP$\n",
      "  daughter/NN\n",
      "  (PERSON Chelsea/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  home/NN\n",
      "  ./.\n",
      "  She/PRP\n",
      "  later/RB\n",
      "  appeared/VBD\n",
      "  outside/JJ\n",
      "  and/CC\n",
      "  was/VBD\n",
      "  driven/VBN\n",
      "  to/TO\n",
      "  her/PRP$\n",
      "  own/JJ\n",
      "  home/NN\n",
      "  in/IN\n",
      "  (GPE Cappaqua/NNP)\n",
      "  ./.\n",
      "  What/WP\n",
      "  impact/NN\n",
      "  will/MD\n",
      "  this/DT\n",
      "  have/VB\n",
      "  on/IN\n",
      "  #/#\n",
      "  hillaryclinton/NN\n",
      "  's/POS\n",
      "  campaign/NN\n",
      "  ?/.\n",
      "  Видео/JJ\n",
      "  опубликовано/NN\n",
      "  RT/NNP\n",
      "  (/(\n",
      "  @/NNP\n",
      "  rt/NN\n",
      "  )/)\n",
      "  Сен/VBZ\n",
      "  12/CD\n",
      "  2016/CD\n",
      "  в/NN\n",
      "  4:09/CD\n",
      "  (ORGANIZATION PDT/NNP)\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/NN\n",
      "  diagnosis/NN\n",
      "  has/VBZ\n",
      "  already/RB\n",
      "  thrown/VBN\n",
      "  her/PRP$\n",
      "  scheduled/VBN\n",
      "  campaign/NN\n",
      "  appearances/NNS\n",
      "  into/IN\n",
      "  disarray/NN\n",
      "  ./.\n",
      "  An/DT\n",
      "  (ORGANIZATION HRC/NNP)\n",
      "  campaign/NN\n",
      "  official/NN\n",
      "  confirmed/VBD\n",
      "  to/TO\n",
      "  (ORGANIZATION Reuters/NNPS)\n",
      "  that/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  canceled/VBD\n",
      "  her/PRP$\n",
      "  Monday/NNP\n",
      "  morning/NN\n",
      "  trip/NN\n",
      "  to/TO\n",
      "  (GPE California/NNP)\n",
      "  because/IN\n",
      "  of/IN\n",
      "  her/PRP$\n",
      "  illness/NN\n",
      "  ./.\n",
      "  She/PRP\n",
      "  was/VBD\n",
      "  set/VBN\n",
      "  to/TO\n",
      "  appear/VB\n",
      "  at/IN\n",
      "  events/NNS\n",
      "  in/IN\n",
      "  both/DT\n",
      "  (PERSON San/NNP Francisco/NNP)\n",
      "  and/CC\n",
      "  (GPE Los/NNP Angeles/NNP)\n",
      "  on/IN\n",
      "  Monday/NNP\n",
      "  and/CC\n",
      "  Tuesday/NNP\n",
      "  ,/,\n",
      "  and/CC\n",
      "  at/IN\n",
      "  a/DT\n",
      "  rally/NN\n",
      "  in/IN\n",
      "  (GPE Las/NNP Vegas/NNP)\n",
      "  ,/,\n",
      "  (GPE Nevada/NNP)\n",
      "  ,/,\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  ./.\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/VBZ\n",
      "  health/NN\n",
      "  became/VBD\n",
      "  the/DT\n",
      "  subject/NN\n",
      "  of/IN\n",
      "  numerous/JJ\n",
      "  articles/NNS\n",
      "  and/CC\n",
      "  conspiracies/NNS\n",
      "  long/RB\n",
      "  before/IN\n",
      "  the/DT\n",
      "  9/11/CD\n",
      "  episode/NN\n",
      "  ./.\n",
      "  Critics/NNS\n",
      "  have/VBP\n",
      "  said/VBD\n",
      "  that/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Democratic/JJ)\n",
      "  campaign/NN\n",
      "  has/VBZ\n",
      "  failed/VBN\n",
      "  to/TO\n",
      "  be/VB\n",
      "  transparent/VBN\n",
      "  on/IN\n",
      "  the/DT\n",
      "  subject/NN\n",
      "  ,/,\n",
      "  adding/VBG\n",
      "  that/IN\n",
      "  this/DT\n",
      "  could/MD\n",
      "  worsen/VB\n",
      "  the/DT\n",
      "  impact/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  news/NN\n",
      "  on/IN\n",
      "  the/DT\n",
      "  election/NN\n",
      "  ’/NNP\n",
      "  s/VBZ\n",
      "  outcome/NN\n",
      "  ./.\n",
      "  #/#\n",
      "  HackingHillary/JJ\n",
      "  :/:\n",
      "  Coughing/NN\n",
      "  fit/NN\n",
      "  causes/NNS\n",
      "  concern/NN\n",
      "  over/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/VBZ\n",
      "  health/NN\n",
      "  ,/,\n",
      "  sparks/VBZ\n",
      "  viral/JJ\n",
      "  hashtags/NNS\n",
      "  https/NN\n",
      "  :/:\n",
      "  //t.co/wHndQJykMPpic.twitter.com/qZtFWcsIx4/JJ\n",
      "  Former/NNP\n",
      "  US/NNP\n",
      "  diplomat/VB\n",
      "  (PERSON Jim/NNP Jatras/NNP)\n",
      "  told/VBD\n",
      "  RT/NNP\n",
      "  a/DT\n",
      "  candidate/NN\n",
      "  ’/NNP\n",
      "  s/VBZ\n",
      "  health/NN\n",
      "  issues/NNS\n",
      "  should/MD\n",
      "  be/VB\n",
      "  deemed/VBN\n",
      "  a/DT\n",
      "  “/JJ\n",
      "  legitimate/JJ\n",
      "  question/NN\n",
      "  ”/NN\n",
      "  as/IN\n",
      "  the/DT\n",
      "  voters/NNS\n",
      "  are/VBP\n",
      "  entitled/VBN\n",
      "  to/TO\n",
      "  know/VB\n",
      "  if/IN\n",
      "  their/PRP$\n",
      "  pick/NN\n",
      "  is/VBZ\n",
      "  100/CD\n",
      "  percent/NN\n",
      "  ready/NN\n",
      "  for/IN\n",
      "  the/DT\n",
      "  role/NN\n",
      "  ./.\n",
      "  He/PRP\n",
      "  believes/VBZ\n",
      "  that/IN\n",
      "  the/DT\n",
      "  (GSP US/NNP)\n",
      "  leader/NN\n",
      "  should/MD\n",
      "  not/RB\n",
      "  be/VB\n",
      "  “/VBN\n",
      "  somebody/NN\n",
      "  who/WP\n",
      "  seems/VBZ\n",
      "  feeble/JJ\n",
      "  and/CC\n",
      "  frail/NN\n",
      "  and/CC\n",
      "  not/RB\n",
      "  up/IN\n",
      "  to/TO\n",
      "  the/DT\n",
      "  job/NN\n",
      "  ,/,\n",
      "  ”/NNP\n",
      "  adding/VBG\n",
      "  that/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/VBZ\n",
      "  health/NN\n",
      "  issues/NNS\n",
      "  are/VBP\n",
      "  obviously/RB\n",
      "  playing/VBG\n",
      "  to/TO\n",
      "  her/PRP$\n",
      "  disadvantage/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  presidential/JJ\n",
      "  race/NN\n",
      "  ./.\n",
      "  Well/NNP\n",
      "  ,/,\n",
      "  pneumonia/NN\n",
      "  ./.\n",
      "  That/DT\n",
      "  's/VBZ\n",
      "  serious/JJ\n",
      "  ./.\n",
      "  (PERSON Campaign/NNP)\n",
      "  kept/VBD\n",
      "  it/PRP\n",
      "  hidden/JJ\n",
      "  Fri/Sat/Sun/NNP\n",
      "  ./.\n",
      "  No/CC\n",
      "  wonder/VB\n",
      "  the/DT\n",
      "  crazies/NNS\n",
      "  get/VBP\n",
      "  traction/NN\n",
      "  ./.\n",
      "  Dems/NNS\n",
      "  are/VBP\n",
      "  pros/NNS\n",
      "  at/IN\n",
      "  losing/VBG\n",
      "  elections/NNS\n",
      "  ./.\n",
      "  (PERSON Jatras/NNP)\n",
      "  believes/VBZ\n",
      "  that/IN\n",
      "  despite/IN\n",
      "  the/DT\n",
      "  current/JJ\n",
      "  uproar/NN\n",
      "  the/DT\n",
      "  (PERSON Clinton/NNP)\n",
      "  campaign/NN\n",
      "  is/VBZ\n",
      "  not/RB\n",
      "  going/VBG\n",
      "  to/TO\n",
      "  change/VB\n",
      "  its/PRP$\n",
      "  tactics/NNS\n",
      "  and/CC\n",
      "  will/MD\n",
      "  try/VB\n",
      "  to/TO\n",
      "  downplay/VB\n",
      "  the/DT\n",
      "  candidate/NN\n",
      "  's/POS\n",
      "  health/NN\n",
      "  troubles/NNS\n",
      "  ,/,\n",
      "  instead/RB\n",
      "  accusing/VBG\n",
      "  the/DT\n",
      "  media/NNS\n",
      "  of/IN\n",
      "  blowing/VBG\n",
      "  them/PRP\n",
      "  out/IN\n",
      "  of/IN\n",
      "  proportion/NN\n",
      "  ./.\n",
      "  “/IN\n",
      "  They/PRP\n",
      "  are/VBP\n",
      "  going/VBG\n",
      "  to/TO\n",
      "  give/VB\n",
      "  out/RP\n",
      "  dribs/NN\n",
      "  and/CC\n",
      "  drabs/NN\n",
      "  of/IN\n",
      "  information/NN\n",
      "  ,/,\n",
      "  that/WDT\n",
      "  try/VBP\n",
      "  to/TO\n",
      "  create/VB\n",
      "  the/DT\n",
      "  best/JJS\n",
      "  possible/JJ\n",
      "  interpretation/NN\n",
      "  of/IN\n",
      "  her/PRP$\n",
      "  health/NN\n",
      "  situation/NN\n",
      "  ,/,\n",
      "  ”/NNP\n",
      "  (PERSON Jatras/NNP)\n",
      "  said/VBD\n",
      "  ,/,\n",
      "  adding/VBG\n",
      "  that/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/NN\n",
      "  team/NN\n",
      "  try/NN\n",
      "  to/TO\n",
      "  “/VB\n",
      "  keep/VB\n",
      "  a/DT\n",
      "  cocoon/NN\n",
      "  ”/VBZ\n",
      "  out/IN\n",
      "  of/IN\n",
      "  fear/NN\n",
      "  that/IN\n",
      "  some/DT\n",
      "  unpleasant/JJ\n",
      "  facts/NNS\n",
      "  can/MD\n",
      "  get/VB\n",
      "  leaked/VBN\n",
      "  to/TO\n",
      "  the/DT\n",
      "  press/NN\n",
      "  ./.\n",
      "  Everybody/NN\n",
      "  knows/VBZ\n",
      "  the/DT\n",
      "  (ORGANIZATION Media/NNP)\n",
      "  and/CC\n",
      "  (ORGANIZATION Democrats/NNPS)\n",
      "  would/MD\n",
      "  bury/VB\n",
      "  this/DT\n",
      "  if/IN\n",
      "  the/DT\n",
      "  video/NN\n",
      "  did/VBD\n",
      "  n't/RB\n",
      "  leak/VB\n",
      "  out/RP\n",
      "  ./.\n",
      "  #/#\n",
      "  HillarysHealthpic.twitter.com/ip2HOrs1O4/NNP\n",
      "  “/NNP\n",
      "  What/WP\n",
      "  's/VBZ\n",
      "  short-lived/JJ\n",
      "  in/IN\n",
      "  this/DT\n",
      "  context/NN\n",
      "  is/VBZ\n",
      "  how/WRB\n",
      "  many/JJ\n",
      "  episodes/NNS\n",
      "  have/VBP\n",
      "  there/RB\n",
      "  been/VBN\n",
      "  that/IN\n",
      "  we/PRP\n",
      "  haven/VBP\n",
      "  ’/JJ\n",
      "  t/NN\n",
      "  seen/VBN\n",
      "  on/IN\n",
      "  camera/NN\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  don/VBP\n",
      "  ’/JJ\n",
      "  t/NN\n",
      "  know/VBP\n",
      "  that/IN\n",
      "  anything/NN\n",
      "  they/PRP\n",
      "  are/VBP\n",
      "  telling/VBG\n",
      "  us/PRP\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  truth/NN\n",
      "  ,/,\n",
      "  ”/CC\n",
      "  he/PRP\n",
      "  argued/VBD\n",
      "  ./.\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/NN\n",
      "  diagnosis/NN\n",
      "  has/VBZ\n",
      "  reignited/VBN\n",
      "  the/DT\n",
      "  #/#\n",
      "  (ORGANIZATION HillaryHealth/NNP)\n",
      "  trend/NN\n",
      "  on/IN\n",
      "  (PERSON Twitter/NNP)\n",
      "  ,/,\n",
      "  with/IN\n",
      "  both/DT\n",
      "  opponents/NNS\n",
      "  and/CC\n",
      "  supporters/NNS\n",
      "  battling/VBG\n",
      "  it/PRP\n",
      "  out/RP\n",
      "  in/IN\n",
      "  posts/NNS\n",
      "  and/CC\n",
      "  comments/NNS\n",
      "  about/IN\n",
      "  who/WP\n",
      "  is/VBZ\n",
      "  now/RB\n",
      "  a/DT\n",
      "  better/JJR\n",
      "  fit/NN\n",
      "  for/IN\n",
      "  president/NN\n",
      "  ./.\n",
      "  (PERSON Pneumonia/NNP)\n",
      "  is/VBZ\n",
      "  very/RB\n",
      "  very/RB\n",
      "  serious/JJ\n",
      "  for/IN\n",
      "  a/DT\n",
      "  68/CD\n",
      "  year/NN\n",
      "  old/JJ\n",
      "  woman/NN\n",
      "  ./.\n",
      "  #/#\n",
      "  (ORGANIZATION HillarysHealth/NNP)\n",
      "  #/#\n",
      "  ClintonCollapsepic.twitter.com/aQT51OlkvY/NNP\n",
      "  While/IN\n",
      "  there/EX\n",
      "  was/VBD\n",
      "  no/DT\n",
      "  immediate/JJ\n",
      "  reaction/NN\n",
      "  from/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/JJ\n",
      "  (ORGANIZATION Republican/NNP)\n",
      "  rival/NN\n",
      "  (PERSON Donald/NNP Trump/NNP)\n",
      "  ,/,\n",
      "  he/PRP\n",
      "  had/VBD\n",
      "  already/RB\n",
      "  used/VBN\n",
      "  the/DT\n",
      "  health/NN\n",
      "  issue/NN\n",
      "  to/TO\n",
      "  score/VB\n",
      "  some/DT\n",
      "  points/NNS\n",
      "  ,/,\n",
      "  including/VBG\n",
      "  during/IN\n",
      "  (PERSON Hillary/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  recent/JJ\n",
      "  “/NN\n",
      "  hacking/NN\n",
      "  ,/,\n",
      "  ”/''\n",
      "  or/CC\n",
      "  coughing/VBG\n",
      "  ,/,\n",
      "  attack/NN\n",
      "  ./.\n",
      "  Mainstream/NNP\n",
      "  media/NNS\n",
      "  never/RB\n",
      "  covered/VBD\n",
      "  (PERSON Hillary/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  massive/JJ\n",
      "  “/NN\n",
      "  hacking/VBG\n",
      "  ”/NN\n",
      "  or/CC\n",
      "  coughing/VBG\n",
      "  attack/NN\n",
      "  ,/,\n",
      "  yet/CC\n",
      "  it/PRP\n",
      "  is/VBZ\n",
      "  #/#\n",
      "  1/CD\n",
      "  trending/NN\n",
      "  ./.\n",
      "  What/WP\n",
      "  ’/VBD\n",
      "  s/VB\n",
      "  up/RP\n",
      "  ?/.\n",
      "  Two/CD\n",
      "  Trump/NN\n",
      "  advisers/NNS\n",
      "  told/VBD\n",
      "  (ORGANIZATION WaPo/NNP)\n",
      "  tonight/VBD\n",
      "  that/IN\n",
      "  the/DT\n",
      "  candidate/NN\n",
      "  &/CC\n",
      "  aides/NNS\n",
      "  are/VBP\n",
      "  closely/RB\n",
      "  monitoring/JJ\n",
      "  (ORGANIZATION HRC/NNP)\n",
      "  news/NN\n",
      "  ./.\n",
      "  But/CC\n",
      "  he/PRP\n",
      "  's/VBZ\n",
      "  not/RB\n",
      "  planning/VBG\n",
      "  to/TO\n",
      "  tweet/VB\n",
      "  ./.\n",
      "  Mentions/NNS\n",
      "  of/IN\n",
      "  former/JJ\n",
      "  (ORGANIZATION Democratic/JJ)\n",
      "  nominee/NN\n",
      "  (PERSON Bernie/NNP Sanders/NNP)\n",
      "  have/VBP\n",
      "  re-emerged/VBN\n",
      "  ,/,\n",
      "  with/IN\n",
      "  his/PRP$\n",
      "  supporters/NNS\n",
      "  questioning/VBG\n",
      "  whether/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  hypothetical/JJ\n",
      "  exit/NN\n",
      "  from/IN\n",
      "  the/DT\n",
      "  race/NN\n",
      "  could/MD\n",
      "  enable/VB\n",
      "  (ORGANIZATION Sanders/NNPS)\n",
      "  to/TO\n",
      "  claim/VB\n",
      "  his/PRP$\n",
      "  candidacy/NN\n",
      "  back/RB\n",
      "  ./.\n",
      "  The/DT\n",
      "  most/RBS\n",
      "  hopeful/JJ\n",
      "  even/RB\n",
      "  postulated/VBD\n",
      "  that/IN\n",
      "  (PERSON Bernie/NNP)\n",
      "  never/RB\n",
      "  technically/RB\n",
      "  gave/VBD\n",
      "  up/RP\n",
      "  his/PRP$\n",
      "  candidacy/NN\n",
      "  when/WRB\n",
      "  endorsing/VBG\n",
      "  (PERSON Clinton/NNP)\n",
      "  ./.\n",
      "  Bring/NNP\n",
      "  back/RB\n",
      "  (PERSON Bernie/NNP)\n",
      "  !/.\n",
      "  #/#\n",
      "  HillarysHealthpic.twitter.com/bgAMGapJyb/NNP\n",
      "  @/NNP\n",
      "  Dallas4Bernie/NNP\n",
      "  @/NNP\n",
      "  jimmy_dore/VBD\n",
      "  It/PRP\n",
      "  's/VBZ\n",
      "  #/#\n",
      "  (ORGANIZATION BernieSanders/NNP Believe/NNP)\n",
      "  me/PRP\n",
      "  !/.\n",
      "  pic.twitter.com/YbY24cgkaE/NN\n",
      "  With/IN\n",
      "  much/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Twitter/NNP)\n",
      "  storm/NN\n",
      "  descending/VBG\n",
      "  into/IN\n",
      "  a/DT\n",
      "  stream/NN\n",
      "  of/IN\n",
      "  “/NN\n",
      "  we/PRP\n",
      "  told/VBD\n",
      "  you/PRP\n",
      "  so/RB\n",
      "  ”/JJ\n",
      "  tweets/NNS\n",
      "  ,/,\n",
      "  some/DT\n",
      "  also/RB\n",
      "  identified/VBN\n",
      "  a/DT\n",
      "  pattern/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Democratic/JJ)\n",
      "  camp/NN\n",
      "  downplaying/VBG\n",
      "  serious/JJ\n",
      "  (PERSON Clinton/NNP)\n",
      "  issues/NNS\n",
      "  ,/,\n",
      "  first/RB\n",
      "  with/IN\n",
      "  her/PRP$\n",
      "  email/NN\n",
      "  scandal/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  then/RB\n",
      "  with/IN\n",
      "  her/PRP$\n",
      "  health/NN\n",
      "  ./.\n",
      "  (PERSON Clinton/NNP)\n",
      "  camp/NN\n",
      "  had/VBD\n",
      "  as/IN\n",
      "  much/JJ\n",
      "  intention/NN\n",
      "  of/IN\n",
      "  telling/VBG\n",
      "  us/PRP\n",
      "  about/IN\n",
      "  her/PRP$\n",
      "  pneumonia/NN\n",
      "  as/IN\n",
      "  they/PRP\n",
      "  did/VBD\n",
      "  of/IN\n",
      "  telling/VBG\n",
      "  us/PRP\n",
      "  about/IN\n",
      "  her/PRP$\n",
      "  server/NN\n",
      "  ./.\n",
      "  Claims/NNS\n",
      "  made/VBN\n",
      "  in/IN\n",
      "  24/CD\n",
      "  hours/NNS\n",
      "  about/RB\n",
      "  #/#\n",
      "  HillarysHealth:1/NNP\n",
      "  )/)\n",
      "  She/PRP\n",
      "  's/VBZ\n",
      "  fine/JJ\n",
      "  !/.\n",
      "  2/CD\n",
      "  )/)\n",
      "  Just/RB\n",
      "  a/DT\n",
      "  cough.3/NN\n",
      "  )/)\n",
      "  Overheated.4/NNP\n",
      "  )/)\n",
      "  Dehydrated.5/NNP\n",
      "  )/)\n",
      "  Pneumonia.What/NNP\n",
      "  's/POS\n",
      "  next/JJ\n",
      "  ?/.\n",
      "  Do/VBP\n",
      "  n't/RB\n",
      "  worry/VB\n",
      "  ,/,\n",
      "  nothing/NN\n",
      "  to/TO\n",
      "  see/VB\n",
      "  here/RB\n",
      "  folks/NNS\n",
      "  ./.\n",
      "  #/#\n",
      "  HillaryHealthpic.twitter.com/7xT7118Bg0/NNP\n",
      "  Some/DT\n",
      "  became/VBD\n",
      "  outraged/VBN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  scene/NN\n",
      "  of/IN\n",
      "  pneumonia-stricken/JJ\n",
      "  (PERSON Clinton/NNP)\n",
      "  talking/VBG\n",
      "  with/IN\n",
      "  and/CC\n",
      "  hugging/VBG\n",
      "  a/DT\n",
      "  little/JJ\n",
      "  girl/NN\n",
      "  seen/VBN\n",
      "  approaching/VBG\n",
      "  the/DT\n",
      "  candidate/NN\n",
      "  during/IN\n",
      "  her/PRP$\n",
      "  “/NN\n",
      "  I/PRP\n",
      "  ’/VBP\n",
      "  m/JJ\n",
      "  feeling/NN\n",
      "  great/JJ\n",
      "  ”/JJ\n",
      "  announcement/NN\n",
      "  ./.\n",
      "  ``/``\n",
      "  I/PRP\n",
      "  have/VBP\n",
      "  pneumonia/VBN\n",
      "  ,/,\n",
      "  but/CC\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  feeling/VBG\n",
      "  great/JJ\n",
      "  !/.\n",
      "  Here/RB\n",
      "  ,/,\n",
      "  let/VB\n",
      "  me/PRP\n",
      "  hug/VB\n",
      "  this/DT\n",
      "  little/JJ\n",
      "  child/NN\n",
      "  ./.\n",
      "  ``/``\n",
      "  #/#\n",
      "  HillarysHealthhttps/NNP\n",
      "  :/:\n",
      "  //t.co/ZKxOTWC1tk/JJ\n",
      "  (PERSON Hillary/NNP Clinton/NNP)\n",
      "  knew/VBD\n",
      "  she/PRP\n",
      "  had/VBD\n",
      "  (GPE Pneumonia/NNP)\n",
      "  (/(\n",
      "  ..VERY/NNP\n",
      "  contagious/RB\n",
      "  )/)\n",
      "  Why/WRB\n",
      "  is/VBZ\n",
      "  she/PRP\n",
      "  hugging/VBG\n",
      "  a/DT\n",
      "  child/NN\n",
      "  for/IN\n",
      "  a/DT\n",
      "  photo/NN\n",
      "  ?/.\n",
      "  !/.\n",
      "  😡/JJ\n",
      "  #/#\n",
      "  HillarysHealthpic.twitter.com/4VuiYuI64N/NNP\n",
      "  Meanwhile/RB\n",
      "  ,/,\n",
      "  (PERSON Hillary/NNP)\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  supporters/NNS\n",
      "  chimed/VBN\n",
      "  in/IN\n",
      "  arguing/VBG\n",
      "  that/IN\n",
      "  (PERSON Clinton/NNP)\n",
      "  ’/NNP\n",
      "  s/NN\n",
      "  lapse/NN\n",
      "  in/IN\n",
      "  health/NN\n",
      "  does/VBZ\n",
      "  not/RB\n",
      "  make/VB\n",
      "  (PERSON Trump/NN)\n",
      "  a/DT\n",
      "  better/JJR\n",
      "  candidate/NN\n",
      "  ,/,\n",
      "  as/IN\n",
      "  her/PRP$\n",
      "  condition/NN\n",
      "  is/VBZ\n",
      "  “/JJ\n",
      "  curable/JJ\n",
      "  ,/,\n",
      "  ”/JJ\n",
      "  unlike/IN\n",
      "  the/DT\n",
      "  personality/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  flamboyant/JJ\n",
      "  (ORGANIZATION Republican/NNP)\n",
      "  nominee/NN\n",
      "  ./.\n",
      "  (PERSON Pneumonia/NNP)\n",
      "  like/IN\n",
      "  (PERSON Hillary/NNP)\n",
      "  's/POS\n",
      "  is/VBZ\n",
      "  curable/JJ\n",
      "  with/IN\n",
      "  a/DT\n",
      "  little/JJ\n",
      "  rest/NN\n",
      "  !/.\n",
      "  But/CC\n",
      "  being/VBG\n",
      "  a/DT\n",
      "  pain/NN\n",
      "  in/IN\n",
      "  people/NNS\n",
      "  's/POS\n",
      "  ass/NN\n",
      "  like/IN\n",
      "  (PERSON Trump/NNP)\n",
      "  is/VBZ\n",
      "  (ORGANIZATION NOT/NNP)\n",
      "  curable/JJ\n",
      "  !/.\n",
      "  https/NN\n",
      "  :/:\n",
      "  //t.co/nF3SJCtFpH/JJ\n",
      "  (PERSON Clinton/NNP)\n",
      "  could/MD\n",
      "  be/VB\n",
      "  diagnosed/VBN\n",
      "  with/IN\n",
      "  every/DT\n",
      "  illness/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  medical/JJ\n",
      "  dictionary/NN\n",
      "  and/CC\n",
      "  she/PRP\n",
      "  would/MD\n",
      "  still/RB\n",
      "  more/RBR\n",
      "  fit/JJ\n",
      "  to/TO\n",
      "  be/VB\n",
      "  (ORGANIZATION POTUS/NNP)\n",
      "  than/IN\n",
      "  Trump./NNP\n",
      "  #/#\n",
      "  (ORGANIZATION HillarysHealth/NNP If/IN Hillary/NNP)\n",
      "  had/VBD\n",
      "  pneumonia/VBN\n",
      "  ,/,\n",
      "  3/CD\n",
      "  drinks/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  1/CD\n",
      "  leg/JJ\n",
      "  stuck/VBN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  bear/JJ\n",
      "  trap/NN\n",
      "  I/PRP\n",
      "  'd/MD\n",
      "  still/RB\n",
      "  have/VB\n",
      "  more/JJR\n",
      "  confidence/NN\n",
      "  in/IN\n",
      "  her/PRP$\n",
      "  than/IN\n",
      "  (PERSON Donald/NNP Trump/NNP)\n",
      "  ./.\n",
      "  #/#\n",
      "  (ORGANIZATION HillaryHealth/NNP))\n"
     ]
    }
   ],
   "source": [
    "# named entity recognition\n",
    "\n",
    "article = dataset[4].split(\"\\t\")[3]\n",
    "\n",
    "# first step you tokenize (read documentation to know the input of NER)\n",
    "article = nltk.word_tokenize(article)\n",
    "\n",
    "# you use the pos-tagger (it gives you back a list of tuples (word,pos))\n",
    "pos_article = nltk.pos_tag(article)\n",
    "\n",
    "# then you use the NER library\n",
    "ner = nltk.ne_chunk(pos_article)\n",
    "\n",
    "print (ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Lisa', 'NNP'), ('R.', 'NNP'), ('Bardack', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('Democratic', 'JJ')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Bardack', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Video', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Nick', 'NNP'), ('Merrill', 'NNP')]), Tree('PERSON', [('Chelsea', 'NNP')]), Tree('GPE', [('Cappaqua', 'NNP')]), Tree('ORGANIZATION', [('PDT', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('HRC', 'NNP')]), Tree('ORGANIZATION', [('Reuters', 'NNPS')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('GPE', [('California', 'NNP')]), Tree('PERSON', [('San', 'NNP'), ('Francisco', 'NNP')]), Tree('GPE', [('Los', 'NNP'), ('Angeles', 'NNP')]), Tree('GPE', [('Las', 'NNP'), ('Vegas', 'NNP')]), Tree('GPE', [('Nevada', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('Democratic', 'JJ')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Jim', 'NNP'), ('Jatras', 'NNP')]), Tree('GSP', [('US', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Campaign', 'NNP')]), Tree('PERSON', [('Jatras', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Jatras', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('Media', 'NNP')]), Tree('ORGANIZATION', [('Democrats', 'NNPS')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('HillaryHealth', 'NNP')]), Tree('PERSON', [('Twitter', 'NNP')]), Tree('PERSON', [('Pneumonia', 'NNP')]), Tree('ORGANIZATION', [('HillarysHealth', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('Republican', 'NNP')]), Tree('PERSON', [('Donald', 'NNP'), ('Trump', 'NNP')]), Tree('PERSON', [('Hillary', 'NNP')]), Tree('PERSON', [('Hillary', 'NNP')]), Tree('ORGANIZATION', [('WaPo', 'NNP')]), Tree('ORGANIZATION', [('HRC', 'NNP')]), Tree('ORGANIZATION', [('Democratic', 'JJ')]), Tree('PERSON', [('Bernie', 'NNP'), ('Sanders', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('Sanders', 'NNPS')]), Tree('PERSON', [('Bernie', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Bernie', 'NNP')]), Tree('ORGANIZATION', [('BernieSanders', 'NNP'), ('Believe', 'NNP')]), Tree('ORGANIZATION', [('Twitter', 'NNP')]), Tree('ORGANIZATION', [('Democratic', 'JJ')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Hillary', 'NNP'), ('Clinton', 'NNP')]), Tree('GPE', [('Pneumonia', 'NNP')]), Tree('PERSON', [('Hillary', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('PERSON', [('Trump', 'NN')]), Tree('ORGANIZATION', [('Republican', 'NNP')]), Tree('PERSON', [('Pneumonia', 'NNP')]), Tree('PERSON', [('Hillary', 'NNP')]), Tree('PERSON', [('Trump', 'NNP')]), Tree('ORGANIZATION', [('NOT', 'NNP')]), Tree('PERSON', [('Clinton', 'NNP')]), Tree('ORGANIZATION', [('POTUS', 'NNP')]), Tree('ORGANIZATION', [('HillarysHealth', 'NNP'), ('If', 'IN'), ('Hillary', 'NNP')]), Tree('PERSON', [('Donald', 'NNP'), ('Trump', 'NNP')]), Tree('ORGANIZATION', [('HillaryHealth', 'NNP')])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner = [x for x in ner if type(x) == nltk.tree.Tree]\n",
    "print (ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Linking\n",
    "\n",
    "- Linked Data is a way of publishing data on the (Semantic) Web \n",
    "- Linked data source created by:  Extracting structured information from Wikipedia, Using “infobox” of the articles \n",
    "- Given a mention of an entity in a document, link it to an entry in a Knowledge Base.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- Not all entities are in knowledge bases\n",
    "- Mentions could be ambiguous\n",
    "\n",
    "Yesterday I watched the debate between Clinton and Sanders. --> which Clinton?\n",
    "\n",
    "**How can we get over this issue?**\n",
    "\n",
    "- Popularity - give me most popular entity\n",
    "- Machine Learning 1 (Similarity between entity and mention)\n",
    "- Machine Learning 2 Joint Assignmnet - if Clinton and Sanders appear together than it must be Hillary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TagMe\n",
    "\n",
    "is a powerful tool that identifies on-the-fly meaningful substrings (called \"spots\") in an unstructured text and link each of them to a pertinent Wikipedia page in an efficient and effective way. You can annotate a text by issuing a query to the API documented in this page.\n",
    "\n",
    "**The annotation service lets you find entities mentioned in a text and link them to Wikipedia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tagme\n",
    "# Set the authorization token for subsequent calls.\n",
    "#https://sobigdata.d4science.org/web/tagme/tagme-help\n",
    "tagme.GCUBE_TOKEN = \"\"\n",
    "\n",
    "article = dataset[4].split(\"\\t\")[3]\n",
    "\n",
    "annotated_article = tagme.annotate(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tagme.AnnotateResponse'>\n"
     ]
    }
   ],
   "source": [
    "print (type(annotated_article))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2124msec, 440 annotations\n"
     ]
    }
   ],
   "source": [
    "print(annotated_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotations are associated a rho-score indicating the likelihood of an annotation being correct\n",
    "In the example, we discard annotations with a score lower than 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr -> Democratic-Republican Party (score: 0.11574618518352509)\n",
      "Clinton -> Bill Clinton (score: 0.18557091057300568)\n",
      "statement -> Press release (score: 0.13940580189228058)\n",
      "Clinton -> Hillary Clinton (score: 0.3210620880126953)\n",
      "Clinton campaign -> Hillary Clinton presidential campaign, 2008 (score: 0.36386874318122864)\n",
      "secretary of state -> United States Secretary of State (score: 0.25825050473213196)\n",
      "pneumonia -> Pneumonia (score: 0.4892668128013611)\n",
      "examination -> Physical examination (score: 0.24207685887813568)\n",
      "cough -> Cough medicine (score: 0.2726736068725586)\n",
      "M.D -> Maryland (score: 0.14633125066757202)\n",
      "Clinton -> Bill Clinton (score: 0.18490441143512726)\n",
      "doctor -> Physician (score: 0.11644203960895538)\n",
      "Democratic -> Democratic Party (United States) (score: 0.22528484463691711)\n",
      "nominee -> Candidate (score: 0.10345222800970078)\n",
      "pneumonia -> Pneumonia (score: 0.29946744441986084)\n",
      "twitter -> Twitter (score: 0.5765565633773804)\n",
      "twitter.com -> Twitter (score: 0.40020275115966797)\n",
      "Clinton -> Hillary Clinton (score: 0.13114146888256073)\n",
      "rest -> Sleep (score: 0.11033379286527634)\n",
      "antibiotics -> Antibiotics (score: 0.1374739110469818)\n",
      "nicely -> Nick Nicely (score: 0.1666666716337204)\n",
      "overheating -> Hyperthermia (score: 0.16813024878501892)\n",
      "dehydration -> Dehydration (score: 0.39095962047576904)\n",
      "Clinton -> Bill Clinton (score: 0.13706165552139282)\n",
      "media -> Growth medium (score: 0.10295592248439789)\n",
      "Video -> Videotape (score: 0.12256423383951187)\n",
      "footage -> Footage (score: 0.13766755163669586)\n",
      "Secretary Clinton -> Hillary Clinton (score: 0.3284839987754822)\n",
      "Clinton -> Bill Clinton (score: 0.25441116094589233)\n",
      "September 11 -> September 11 attacks (score: 0.12783336639404297)\n",
      "Commemoration -> Commemoration (prayer) (score: 0.21717195212841034)\n",
      "Ceremony -> Ceremony (score: 0.18543797731399536)\n",
      "hour -> Liturgy of the Hours (score: 0.14384524524211884)\n",
      "this morning -> This Morning (TV programme) (score: 0.16348068416118622)\n",
      "spokesman -> Spokesperson (score: 0.1271725445985794)\n",
      "Nick Merrill -> Nicholas Merrill (score: 0.1666666716337204)\n",
      "Chelsea -> Chelsea F.C. (score: 0.38828128576278687)\n",
      "RT -> Tackle (gridiron football position) (score: 0.14163938164710999)\n",
      "PDT -> Pacific Time Zone (score: 0.48943817615509033)\n",
      "Clinton -> Clinton, British Columbia (score: 0.17594598233699799)\n",
      "HRC -> Human rights commission (score: 0.15405967831611633)\n",
      "campaign -> Political campaign (score: 0.13299208879470825)\n",
      "official -> Official (score: 0.1377965360879898)\n",
      "confirmed -> Supreme Court of the United States (score: 0.18962904810905457)\n",
      "Reuters -> Reuters (score: 0.4327102303504944)\n",
      "Clinton -> Bill Clinton (score: 0.11064089834690094)\n",
      "trip -> Psychedelic experience (score: 0.1143672913312912)\n",
      "California -> California (score: 0.192306786775589)\n",
      "San Francisco -> San Francisco (score: 0.4439185857772827)\n",
      "Los Angeles -> Los Angeles (score: 0.16983450949192047)\n",
      "Monday -> Monday (score: 0.23918819427490234)\n",
      "Tuesday -> Tuesday (score: 0.16253535449504852)\n",
      "Las Vegas, Nevada -> Las Vegas (score: 0.5)\n",
      "Nevada -> Nevada (score: 0.34565553069114685)\n",
      "Wednesday -> Wednesday Night Baseball (score: 0.11362924426794052)\n",
      "Clinton -> Bill Clinton (score: 0.1461564153432846)\n",
      "health -> Health (score: 0.10639415681362152)\n",
      "subject -> Citizenship (score: 0.16536954045295715)\n",
      "Critics -> Film criticism (score: 0.15091872215270996)\n",
      "Democratic -> Democracy (score: 0.21798419952392578)\n",
      "campaign -> Political campaign (score: 0.18362784385681152)\n",
      "outcome -> Prognosis (score: 0.1907465010881424)\n",
      "Coughing -> Cough (score: 0.2951262593269348)\n",
      "fit -> Epileptic seizure (score: 0.2740893065929413)\n",
      "causes -> Paralysis (score: 0.20002664625644684)\n",
      "sparks -> Sparks (band) (score: 0.10721549391746521)\n",
      "viral -> Viral license (score: 0.19652055203914642)\n",
      "hashtags -> Hashtag (score: 0.325752854347229)\n",
      "https -> HTTPS (score: 0.5251719355583191)\n",
      "t.co -> Twitter (score: 0.7118765115737915)\n",
      "twitter -> Twitter (score: 0.7888914346694946)\n",
      "twitter.com -> Twitter (score: 0.3783401846885681)\n",
      "US -> United States dollar (score: 0.14452430605888367)\n",
      "diplomat -> Diplomacy (score: 0.12231557071208954)\n",
      "Jatras -> Jatra (theatre) (score: 0.11764705926179886)\n",
      "RT -> RT (TV network) (score: 0.1245935708284378)\n",
      "candidate -> Candidate of Sciences (score: 0.2868082523345947)\n",
      "candidate’s -> Candidate of Sciences (score: 0.2361571490764618)\n",
      "health -> Public health (score: 0.17891231179237366)\n",
      "be “somebody -> List of Cracker episodes (score: 0.3888888955116272)\n",
      "who -> The Who (score: 0.11129612475633621)\n",
      "frail -> Jars of Clay (score: 0.17657853662967682)\n",
      "up -> Up (TV network) (score: 0.235032856464386)\n",
      "job -> The Job (2013 TV series) (score: 0.23757784068584442)\n",
      "Clinton -> Bill Clinton (score: 0.20097728073596954)\n",
      "pneumonia -> Pneumonia (score: 0.3498021364212036)\n",
      "Campaign -> Civil society campaign (score: 0.17121772468090057)\n",
      "crazies -> The Crazies (2010 film) (score: 0.24473683536052704)\n",
      "Dems -> Defensively equipped merchant ship (score: 0.11716621369123459)\n",
      "Jatras -> Jatra (theatre) (score: 0.11764705926179886)\n",
      "Clinton -> Hillary Clinton (score: 0.22832338511943817)\n",
      "Clinton campaign -> Hillary Clinton presidential campaign, 2008 (score: 0.2157074362039566)\n",
      "change -> Social change (score: 0.2391877919435501)\n",
      "tactics -> Military tactics (score: 0.155891552567482)\n",
      "will -> Free will (score: 0.11004620045423508)\n",
      "candidate -> Candidate of Sciences (score: 0.24290242791175842)\n",
      "candidate's -> Candidate of Sciences (score: 0.2407442033290863)\n",
      "health -> Health education (score: 0.15512719750404358)\n",
      "troubles -> The Troubles (score: 0.1104511171579361)\n",
      "media -> News media (score: 0.11032475531101227)\n",
      "try -> Try (score: 0.20200401544570923)\n",
      "interpretation -> Music (score: 0.15327636897563934)\n",
      "Jatras -> Jatra (theatre) (score: 0.11764705926179886)\n",
      "Clinton -> Clinton, South Carolina (score: 0.1417725831270218)\n",
      "team -> Team (score: 0.14551867544651031)\n",
      "keep -> The Keep (film) (score: 0.2038612961769104)\n",
      "cocoon -> Cocoon (film) (score: 0.3152350187301636)\n",
      "fear -> Fear (score: 0.23932301998138428)\n",
      "unpleasant -> Disgust (score: 0.26891863346099854)\n",
      "facts -> Fact (score: 0.1266348510980606)\n",
      "can -> Can (band) (score: 0.15610508620738983)\n",
      "leaked -> Internet leak (score: 0.2030729204416275)\n",
      "press -> Music journalism (score: 0.15064170956611633)\n",
      "Democrats -> Democracy (score: 0.13933447003364563)\n",
      "bury -> Bury F.C. (score: 0.1450628936290741)\n",
      "if -> If (Janet Jackson song) (score: 0.16458000242710114)\n",
      "video -> Music video (score: 0.1622932404279709)\n",
      "leak -> Internet leak (score: 0.25197407603263855)\n",
      "out -> Out (magazine) (score: 0.17878571152687073)\n",
      "twitter -> Twitter (score: 0.5728030204772949)\n",
      "twitter.com -> Twitter (score: 0.39849990606307983)\n",
      "episodes -> Rubicon (TV series) (score: 0.10787732154130936)\n",
      "we -> WE tv (score: 0.17973309755325317)\n",
      "haven -> Haven (TV series) (score: 0.14014190435409546)\n",
      "camera -> Camera (2000 film) (score: 0.15953829884529114)\n",
      "us -> Billboard 200 (score: 0.13947290182113647)\n",
      "diagnosis -> Cancer (score: 0.11011095345020294)\n",
      "Twitter -> Twitter (score: 0.33750903606414795)\n",
      "Pneumonia -> Pneumonia (score: 0.3189495801925659)\n",
      "old woman -> Donor (fairy tale) (score: 0.11949287354946136)\n",
      "woman -> Woman (score: 0.12078110128641129)\n",
      "twitter -> Twitter (score: 0.47547024488449097)\n",
      "twitter.com -> Twitter (score: 0.35029077529907227)\n",
      "Republican -> Republican Party (United States) (score: 0.36112093925476074)\n",
      "Donald Trump -> Donald Trump (score: 0.73516845703125)\n",
      "health -> Health care (score: 0.18161383271217346)\n",
      "issue -> Child (score: 0.15267373621463776)\n",
      "hacking -> Hacker (computer security) (score: 0.11396229267120361)\n",
      "attack -> September 11 attacks (score: 0.1362185925245285)\n",
      "Mainstream media -> Mass media (score: 0.21112599968910217)\n",
      "hacking -> Hacker (computer security) (score: 0.11396229267120361)\n",
      "attack -> Offensive (military) (score: 0.14035628736019135)\n",
      "What’s up -> What's Up (TV series) (score: 0.20459190011024475)\n",
      "WaPo -> The Washington Post (score: 0.2624909281730652)\n",
      "HRC -> Human Rights Campaign (score: 0.1246505081653595)\n",
      "tweet -> Twitter (score: 0.20423074066638947)\n",
      "Democratic -> Democracy (score: 0.16311779618263245)\n",
      "nominee -> Candidate (score: 0.19008326530456543)\n",
      "Bernie Sanders -> Bernie Sanders (score: 0.6950542330741882)\n",
      "supporters -> Populares (score: 0.17411081492900848)\n",
      "questioning -> Questioning (sexuality and gender) (score: 0.1749785989522934)\n",
      "Clinton -> Bill Clinton (score: 0.11955282092094421)\n",
      "race -> Race (human categorization) (score: 0.1443008929491043)\n",
      "Sanders -> Bernie Sanders (score: 0.13750281929969788)\n",
      "his candidacy -> Rand Paul presidential campaign, 2016 (score: 0.33883512020111084)\n",
      "candidacy -> Jeb Bush presidential campaign, 2016 (score: 0.20916254818439484)\n",
      "his candidacy -> Rand Paul presidential campaign, 2016 (score: 0.16756059229373932)\n",
      "candidacy -> Jeb Bush presidential campaign, 2016 (score: 0.1700008511543274)\n",
      "Clinton -> Hillary Clinton (score: 0.205499529838562)\n",
      "twitter -> Twitter (score: 0.6016885042190552)\n",
      "twitter.com -> Twitter (score: 0.3832195997238159)\n",
      "jimmy_dore -> Jimmy Dore (score: 0.4375)\n",
      "twitter -> Twitter (score: 0.5765565633773804)\n",
      "twitter.com -> Twitter (score: 0.3580877184867859)\n",
      "Democratic -> Democracy (score: 0.17533253133296967)\n",
      "Democratic camp -> Pan-democracy camp (score: 0.12248155474662781)\n",
      "Clinton -> Hillary Clinton (score: 0.21749798953533173)\n",
      "issues -> On the Issues (score: 0.16001926362514496)\n",
      "first -> First Amendment to the United States Constitution (score: 0.21118517220020294)\n",
      "email -> Email (score: 0.23997759819030762)\n",
      "scandal -> Lewinsky scandal (score: 0.19425030052661896)\n",
      "health -> Health care (score: 0.16437724232673645)\n",
      "Clinton -> Bill Clinton (score: 0.2153116762638092)\n",
      "camp -> Camp (style) (score: 0.11281536519527435)\n",
      "intention -> Intention (score: 0.10896559059619904)\n",
      "pneumonia -> Pneumonia (score: 0.3443889319896698)\n",
      "She's fine -> Halle Berry (She's Fine) (score: 0.10810811072587967)\n",
      "cough -> Cough (score: 0.21250957250595093)\n",
      "Dehydrated -> Dehydration (score: 0.31197282671928406)\n",
      "Pneumonia -> Pneumonia (score: 0.44563621282577515)\n",
      "twitter -> Twitter (score: 0.5388914346694946)\n",
      "twitter.com -> Twitter (score: 0.32042253017425537)\n",
      "the scene -> The Scene (miniseries) (score: 0.1875)\n",
      "pneumonia -> Pneumonia (score: 0.3206478953361511)\n",
      "t.co -> Twitter (score: 0.3333333432674408)\n",
      "Hillary Clinton -> Hillary Clinton (score: 0.5)\n",
      "Pneumonia -> Pneumonia (score: 0.4184996485710144)\n",
      "contagious -> Infection (score: 0.13100585341453552)\n",
      "child -> Child (score: 0.12655813992023468)\n",
      "twitter -> Twitter (score: 0.47315484285354614)\n",
      "twitter.com -> Twitter (score: 0.34336885809898376)\n",
      "Clinton -> Hillary Clinton (score: 0.35678163170814514)\n",
      "health -> Health care (score: 0.17339853942394257)\n",
      "Trump -> Donald Trump (score: 0.1379559338092804)\n",
      "flamboyant -> Camp (style) (score: 0.13364599645137787)\n",
      "Republican -> Republicanism (score: 0.3810114860534668)\n",
      "nominee -> Candidate (score: 0.12174869328737259)\n",
      "Pneumonia -> Pneumonia (score: 0.38399967551231384)\n",
      "Hillary -> Hillary Clinton (score: 0.12568268179893494)\n",
      "pain -> Suffering (score: 0.2503458857536316)\n",
      "people -> Person (score: 0.1674003005027771)\n",
      "ass -> Buttocks (score: 0.1832318753004074)\n",
      "Trump -> Donald Trump (score: 0.13496161997318268)\n",
      "https -> HTTPS (score: 0.39057061076164246)\n",
      "t.co -> Twitter (score: 0.4011480212211609)\n",
      "Clinton -> Bill Clinton (score: 0.12025894224643707)\n",
      "illness -> Disease (score: 0.10625557601451874)\n",
      "medical dictionary -> Medical dictionary (score: 0.22499150037765503)\n",
      "POTUS -> President of the United States (score: 0.6041046977043152)\n",
      "Trump -> Donald Trump (score: 0.14456114172935486)\n",
      "If -> If... (comic) (score: 0.11659412086009979)\n",
      "Hillary -> Hillary Clinton (score: 0.23346863687038422)\n",
      "pneumonia -> Pneumonia (score: 0.36444416642189026)\n",
      "I'd -> I-D (score: 0.11003953218460083)\n",
      "Donald Trump -> Donald Trump (score: 0.670127272605896)\n"
     ]
    }
   ],
   "source": [
    "for ann in annotated_article.get_annotations(0.1): \n",
    "    print (ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debate -> United States presidential election debates (score: 0.1599879115819931)\n",
      "Clinton -> Bill Clinton (score: 0.22683759033679962)\n",
      "Sanders -> Bernie Sanders (score: 0.19481973350048065)\n"
     ]
    }
   ],
   "source": [
    "# test with this\n",
    "sent = tagme.annotate(\"Yesterday I watched the debate between Clinton and Sanders.\")\n",
    "\n",
    "# Print annotations with a score higher than 0.1\n",
    "for ann in sent.get_annotations(0.1):\n",
    "    print (ann)\n",
    "\n",
    "# why is it still making mistakes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillary and Bernie have a semantic relation of 0.7044501304626465\n",
      "Bill and Bernie have a semantic relation of 0.5230528116226196\n",
      "Bill and Hillary have a semantic relation of 0.7114993929862976\n"
     ]
    }
   ],
   "source": [
    "# computing entity relatedness\n",
    "rels = tagme.relatedness_title((\"Hillary Clinton\", \"Bernie Sanders\"))\n",
    "print (\"Hillary and Bernie have a semantic relation of\", rels.relatedness[0].rel)\n",
    "\n",
    "rels = tagme.relatedness_title((\"Bill Clinton\", \"Bernie Sanders\"))\n",
    "print (\"Bill and Bernie have a semantic relation of\", rels.relatedness[0].rel)\n",
    "\n",
    "rels = tagme.relatedness_title((\"Bill Clinton\", \"Hillary Clinton\"))\n",
    "print (\"Bill and Hillary have a semantic relation of\", rels.relatedness[0].rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 1**\n",
    "\n",
    "Using sascat_excerpt.tsv data\n",
    "\n",
    "- a- use a cleaning pipeline that you see suitable on the content\n",
    "- b- check how many unique words (after cleaning step) in the sanctions dataset\n",
    "- c- count most frequent 50 words and comment on it (note that these are sanctions laws, why are these words frequent?)\n",
    "- d- evaluate your cleaning method, after seeing the result of teh most frequent words would change your cleaning technique?\n",
    "- e- plot the 20 most common words using matlapplot\n",
    "- f- what are the most frequent 10 NERs here (use unclean text)? Do they make sense to you? \n",
    "- g- plot the most common 20 NERs and compare to the plot of the 20 most common words plot\n",
    "- h- could you have cleaned the content before finding the NERs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 2**\n",
    "\n",
    "Use Donald Trump tweets and improve his vocabulary by finding for his poor choice of adjectives - more sophisticated synonyms (e.g. \"[bad] ratings on the Emmys last night\" -> \"[substandard] ratings on the Emmys last night\")\n",
    "\n",
    "\n",
    "Hints:\n",
    "- check how to process a json file\n",
    "- text processing (POS tagging + WordNet)\n",
    "- discover how you can do this through wordnet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 3**\n",
    "\n",
    "Make Donlald Trump tweets (use trump.json) nicer by finding adjectives with related antonyms (e.g. \"bad ratings on the Emmys last night\" -> \"excellent ratings on the Emmys last night\")\n",
    "\n",
    "to do you need to combine:\n",
    "\n",
    "- text processing (POS tagging + WordNet)\n",
    "- check how to process a json file\n",
    "- Hint: discover how you can do this through wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 4**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the most popular 30 NERs (not entities!) from the entire corpus of the rt_dataset.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
